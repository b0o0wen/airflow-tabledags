#文件目录结构
要么按文件类型分，要么按task分
    - 结论:所有.sql .sh 文件放在一个目录下，方便redo
    - subdag 的.py 在一个文件夹subdags 但subdag的 .sh .sql 还是与其他在一起

目录结构设计如下：

- mainpy.py
- scripts
    + .sh
    + .sql
- subdags
    + subdag1.py
    + subdag2.py


# 脚本步骤
1. 根据scripts 下sql文件名，生成对应的sh log
2. 对于带weekly monthly 的sql文件名，生成对于 subdag
3. 解析所以sql，生成依赖关系，写入pg
4. 写mainpy: 写头部，写dag 或 subdag，读pg 写依赖


# 脚本中命名约定
rootdir 是dag的路径，如20.96上 '/root/airflow/dags/himalaya/' 谨记以 / 结尾
mainpy 是核心.py 的文件名，同时也是 DAG_NAME， 如 himalaya
core_name 是task名，也是表名，很core 所以叫core_name，如 base_event
sql_path = rootdir+'scripts/'+core_name+'.sql'
sh_path = rootdir+'scripts/'+core_name+'.sh'
log_path = rootdir+'scripts/'+core_name+'.log'
subdag_path = rootdir+'subdags/'+core_name+'.py'




# 待观察问题
- 留存是有脚本循环来跑还是用lead lag 来跑好
